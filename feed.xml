<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2023-04-15T12:57:58-05:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">loighic.net</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
</subtitle><entry><title type="html">articles about teaching</title><link href="http://localhost:4000/blog/2022/articles-on-teaching/" rel="alternate" type="text/html" title="articles about teaching" /><published>2022-08-14T00:00:00-05:00</published><updated>2022-08-14T00:00:00-05:00</updated><id>http://localhost:4000/blog/2022/articles-on-teaching</id><content type="html" xml:base="http://localhost:4000/blog/2022/articles-on-teaching/">&lt;p&gt;Since I’ve been teaching, I’ve occasionally posted articles about it that I like on the various sites that I’ve had. (Miss you, Google+ page!) So, anyway, here are some of them all in one place.&lt;/p&gt;

&lt;hr style=&quot;opacity:0&quot; /&gt;

&lt;div class=&quot;iframely-embed&quot;&gt;&lt;div class=&quot;iframely-responsive&quot; style=&quot;height: 140px; padding-bottom: 0;&quot;&gt;&lt;a href=&quot;https://www.wired.com/2013/10/free-thinkers/&quot; data-iframely-url=&quot;//iframely.net/A48sokJ?card=small&quot;&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;
&lt;script async=&quot;&quot; src=&quot;//iframely.net/embed.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;This video is part of an interview with Demis Hassabis, the co-founder and CEO of Google’s &lt;a href=&quot;https://www.youtube.com/channel/UCP7jMXSY2xbc3KCAE0MHQ-A&quot;&gt;DeepMind&lt;/a&gt; (also check out &lt;a href=&quot;https://youtu.be/gg7WjuFs8F4&quot;&gt;AlphaFold: The making of a scientific breakthrough&lt;/a&gt;). This part of the interview is his take on undergraduate and graduate education.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/1X7Koxx4qJE?start=2113&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt; &lt;/p&gt;

&lt;div class=&quot;iframely-embed&quot;&gt;&lt;div class=&quot;iframely-responsive&quot; style=&quot;height: 140px; padding-bottom: 0;&quot;&gt;&lt;a href=&quot;https://www.npr.org/sections/health-shots/2012/11/12/164793058/struggle-for-smarts-how-eastern-and-western-cultures-tackle-learning&quot; data-iframely-url=&quot;//iframely.net/3sh2Tnm?card=small&quot;&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;
&lt;script async=&quot;&quot; src=&quot;//iframely.net/embed.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;div class=&quot;iframely-embed&quot;&gt;&lt;div class=&quot;iframely-responsive&quot; style=&quot;height: 140px; padding-bottom: 0;&quot;&gt;&lt;a href=&quot;https://www.wsj.com/articles/the-case-for-a-college-exit-exam-11628690410&quot; data-iframely-url=&quot;//iframely.net/Xm2iuRb?card=small&quot;&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;
&lt;script async=&quot;&quot; src=&quot;//iframely.net/embed.js&quot;&gt;&lt;/script&gt;

&lt;div class=&quot;iframely-embed&quot;&gt;&lt;div class=&quot;iframely-responsive&quot; style=&quot;padding-bottom: 56.25%; padding-top: 120px;&quot;&gt;&lt;a href=&quot;https://www.nytimes.com/2017/12/03/opinion/lost-einsteins-innovation-inequality.html&quot; data-iframely-url=&quot;//cdn.iframe.ly/api/iframe?media=0&amp;amp;url=https%3A%2F%2Fwww.nytimes.com%2F2017%2F12%2F03%2Fopinion%2Flost-einsteins-innovation-inequality.html&amp;amp;key=681ecff6a27093061ce9f2d441604d33&quot;&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;
&lt;script async=&quot;&quot; src=&quot;//cdn.iframe.ly/embed.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;div class=&quot;iframely-embed&quot;&gt;&lt;div class=&quot;iframely-responsive&quot; style=&quot;height: 140px; padding-bottom: 0;&quot;&gt;&lt;a href=&quot;https://www.wired.com/2013/10/telling-you-the-answer-isnt-the-answer/&quot; data-iframely-url=&quot;//iframely.net/3D6iHci?card=small&quot;&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;
&lt;script async=&quot;&quot; src=&quot;//iframely.net/embed.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;hr style=&quot;opacity:0&quot; /&gt;

&lt;h5&gt;&lt;b&gt;Are colleges failing?&lt;/b&gt;&lt;/h5&gt;
&lt;p&gt;Higher ed needs new lesson plans. A remarkable feature of American colleges is the lack of attention that most faculties pay to the growing body of research about how much students are learning and how they could be taught to learn more.
Read the article on &lt;a href=&quot;http://archive.boston.com/news/globe/editorial_opinion/oped/articles/2005/12/18/are_colleges_failing/&quot;&gt;archive.boston.com&lt;/a&gt;&lt;/p&gt;

&lt;hr style=&quot;opacity:0&quot; /&gt;

&lt;h5&gt;&lt;b&gt;The Shadow Scholar&lt;/b&gt;&lt;/h5&gt;

&lt;h5&gt;The man who writes your students’ papers tells his story&lt;/h5&gt;

&lt;p&gt;The request came in by e-mail around 2 in the afternoon. It was from a previous customer, and she had urgent business. I quote her message here verbatim (if I had to put up with it, so should you): “You did me business ethics propsal for me I need propsal got approved pls can you will write me paper?”&lt;/p&gt;

&lt;p&gt;Read the full &lt;a href=&quot;https://www.chronicle.com/article/the-shadow-scholar/&quot;&gt;article&lt;/a&gt;. Login required.&lt;/p&gt;

&lt;hr style=&quot;opacity:0&quot; /&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/dGCJ46vyR9o&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt; &lt;/p&gt;</content><author><name></name></author><summary type="html">Since I’ve been teaching, I’ve occasionally posted articles about it that I like on the various sites that I’ve had. (Miss you, Google+ page!) So, anyway, here are some of them all in one place.</summary></entry><entry><title type="html">a short introduction to functionalism</title><link href="http://localhost:4000/blog/2022/functionalism/" rel="alternate" type="text/html" title="a short introduction to functionalism" /><published>2022-03-18T00:00:00-05:00</published><updated>2022-03-18T00:00:00-05:00</updated><id>http://localhost:4000/blog/2022/functionalism</id><content type="html" xml:base="http://localhost:4000/blog/2022/functionalism/">&lt;p&gt;These two sections were part of a &lt;a href=&quot;https://loighic.net/projects/2_project/&quot;&gt;chapter on the mind&lt;/a&gt;. I re-wrote them for the current version of the chapter so that the presentation of functionalism would be a little less technical. This version might still be of interest, however, to anyone looking for a (very) short introduction to the topic. So, here they are.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;  &lt;/p&gt;

&lt;h5 id=&quot;4-functionalism&quot;&gt;&lt;strong&gt;4. Functionalism&lt;/strong&gt;&lt;/h5&gt;

&lt;p&gt;Monism—the idea that the universe is composed of only one substance, matter—is really a category of theories. The version of monism that dominated the second half of the twentieth century began with the philosopher Hilary Putnam’s observation that a mental state such as pain can be experienced by very different kinds of creatures. His examples were mammals, reptiles, octopuses (which are a type of mollusk), and aliens. The first three have, here on earth, taken different evolutionary paths, and so their brains are not that similar. (Of course, the brain of a cat and the brain of a primate are not that similar either, but since they are both mammals and share an evolutionary history, their brains are more similar to each other than either is to a reptile or a mollusk.) Still, mammals, reptiles, and octopuses can all experience pain. And an alien will have yet another type of brain but can still, presumably, experience pain.&lt;/p&gt;

&lt;p&gt;Putnam’s response to this observation was to suggest that pain and all other mental states should not—and, in fact, could not—be defined as cellular or molecular or chemical states of the brain. Rather they should be defined in terms of how they &lt;em&gt;function&lt;/em&gt;. Pain is not “c-fibers firing” (to use a popular example in the philosophical literature). It is rather the mental state that causes me to say “ouch” and pull back from the stimulus causing the pain.&lt;/p&gt;

&lt;p&gt;Before going any further, let’s think a little more about the difference between &lt;em&gt;function&lt;/em&gt; and &lt;em&gt;structure&lt;/em&gt;. Sitting on my desk is a pen that is mostly made of plastic. The cylinder is clear, the cap is blue, inside the cylinder is a thin tube filled with blue ink, and, at the tip of the pen, is a small ball made of tungsten carbide. Those features of the pen—a cylinder a little over 5 inches long and a quarter of an inch in diameter, a small ball at one end, and so forth—are structural features. Without them, the pen wouldn’t exist. But what makes a pen a pen is the &lt;em&gt;function&lt;/em&gt; (or the &lt;em&gt;task&lt;/em&gt; or the &lt;em&gt;job&lt;/em&gt;) that it performs, not it’s specific structural features. It has only one function: &lt;em&gt;facilitating the manual application of ink to a surface&lt;/em&gt;, but various structures can perform this function. Instead of plastic, a pen can be made of metal, reed, or a large feather. Instead of a quarter inch in diameter, it can be wider or narrower. Instead of a ball on the end it, it can have a nib (as fountain pens do), a felt tip, or the sharpened end of a feather. But whatever its structure, as long as it performs the correct function, it’s a pen. That insight, that certain things are defined in terms of their function, is the core idea for this theory of the mind, which is called, appropriately enough, &lt;em&gt;functionalism&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;So, if I tried to define a pen as &lt;em&gt;a clear plastic cylinder, a little over 5 inches long, a quarter of an inch in diameter, with a small tungsten carbide ball at one end, and blue ink stored in a tube inside the cylinder&lt;/em&gt;, that definition would be incorrect. It’s a description of some pens, but since it leaves out many other instruments that count as pens, it fails as a definition. In other words, pens are &lt;em&gt;multiply realized&lt;/em&gt;—that is, there are multiple structures that &lt;em&gt;realize&lt;/em&gt; (or &lt;em&gt;instantiate&lt;/em&gt;) the function &lt;em&gt;facilitating the manual application of ink to a surface&lt;/em&gt;. Similarly, at least according to Putnam and many other philosophers, pain and all other mental states are multiply realized. Pain can be instantiated in the mammalian brain, in the reptile brain, in the mollusk brain, and even, presumably, in the alien brain. Consequently, if we try to define pain as a particular sort of activity in the human brain, that definition will be wrong because it leaves out the other kinds of neural activity that are pain in other species.&lt;/p&gt;

&lt;p&gt;We’ll return to functionalism, but let’s clarify one more thing first. By &lt;em&gt;mental states&lt;/em&gt;, we mean, for instance, beliefs, desires (i.e., wants), thoughts, ideas (although thoughts and ideas may be the same as beliefs), intentions, sensations, and emotions. Most mental states, although not all, have content. For instance, my &lt;em&gt;belief that today is Thursday&lt;/em&gt; is a belief that has the content &lt;em&gt;today is Thursday&lt;/em&gt;. Similarly, my &lt;em&gt;desire that it snow this weekend&lt;/em&gt; is a desire with the content &lt;em&gt;it snow this weekend&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Functionalism holds that mental states are functional states. It is still a version of monism, though, so it agrees that—just as a pen has to be instantiated in some physical object—mental states are instantiated in the brain. But, according to functionalism, we don’t have to—in fact, it would be wrong to—define mental states as particular states of the brain. That gives functionalism a certain appeal. First, because it is a version of monism, it doesn’t have any of the problems that dualism encountered. Second, it allows us to characterize the mind in a way that is very familiar to us. I feel (a mental state!) as though I have beliefs, desires, hopes, fears, and so forth. Furthermore, those mental states, just as Descartes said, seem to define who I am. I might be disappointed if the best theory of the mind told me that the mind is really just a series of neurons firing in the brain. Some people would be more than just disappointed. The philosopher Jerry Fodor, who along with Putnam was instrumental in developing functionalism, says at one point, “if it isn’t literally true that my wanting is causally responsible for my reaching, and my itching is causally responsible for my scratching, and my believing is causally responsible for my saying . . . if none of that is literally true, then practically everything I believe about anything is false and it’s the end of the world.”&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; But luckily for Fodor, functionalism tells us that beliefs, desires, sensations, emotions, and so forth are real and have scientific credibility.&lt;/p&gt;

&lt;p&gt;Consider another non-mental example, but one that is more complex than a pen. Here is a simplified description of how a car runs:&lt;/p&gt;

&lt;blockquote&gt;

  &lt;p&gt;The &lt;strong&gt;fuel injector&lt;/strong&gt; sprays a mixture of air and gasoline at the &lt;strong&gt;intake valve&lt;/strong&gt;. The &lt;strong&gt;intake valve&lt;/strong&gt; opens letting the air-gas mixture into the &lt;strong&gt;cylinder chamber&lt;/strong&gt;. The &lt;strong&gt;piston&lt;/strong&gt; compresses the air-gasoline mixture. The &lt;strong&gt;spark plug&lt;/strong&gt; emits a spark that ignites the gasoline, which drives the &lt;strong&gt;piston&lt;/strong&gt; down the &lt;strong&gt;cylinder chamber&lt;/strong&gt;. The downward movement of the &lt;strong&gt;piston&lt;/strong&gt; turns the &lt;strong&gt;crankshaft&lt;/strong&gt;, which turns the wheels.&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;Notice that each component in this system is described in terms of what it does—that is, it’s function—not what it is made of. For instance, based on this description, we have no idea what an intake valve looks like or how it is constructed. But that doesn’t really seem to matter because we know that an intake valve is the component that lets the air-gas mixture pass from the fuel injector into the cylinder chamber. &lt;em&gt;Letting the air-gas mixture into the cylinder chamber&lt;/em&gt; is the intake valve’s function, and, perhaps, to understand what an intake valve is, that’s all we need to know.&lt;/p&gt;

&lt;p&gt;Now, a mental example:&lt;/p&gt;

&lt;blockquote&gt;

  &lt;p&gt;I look at the clock and see that it is 6:00 pm. Seeing that it is 6:00 pm causes &lt;strong&gt;the belief that it is 6:00 pm&lt;/strong&gt; which causes the &lt;strong&gt;thought that it’s time to stop working&lt;/strong&gt; and the &lt;strong&gt;desire for a beer&lt;/strong&gt;. I already have the &lt;strong&gt;belief that there is a beer in the refrigerator&lt;/strong&gt;, and so &lt;strong&gt;the belief that there is a beer in the refrigerator&lt;/strong&gt; plus my &lt;strong&gt;desire for a beer&lt;/strong&gt; cause me to get up and walk toward the kitchen.&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;The mental states are &lt;em&gt;the belief that it is 6:00 pm&lt;/em&gt;, &lt;em&gt;the thought that it’s time to stop working&lt;/em&gt;, &lt;em&gt;the desire for a beer&lt;/em&gt;, and &lt;em&gt;the belief that there is a beer in the refrigerator&lt;/em&gt;. According to functionalism, this little scenario is the way that we define these mental states. The &lt;em&gt;desire for a beer&lt;/em&gt;, at least for me, is the mental state that is caused by &lt;em&gt;the belief that it is 6:00 pm&lt;/em&gt; and causes the action: &lt;em&gt;walking into the kitchen&lt;/em&gt;. That’s a functional characterization of my desire for a beer.&lt;/p&gt;

&lt;p&gt;Of course, to be made complete, the description would have to include all of the mental states that can cause the desire for a beer and all of the other mental states and actions that this desire causes. It would also have to include the caveat that the belief that it is 6:00 pm won’t always cause the desire for a beer. I have to have the belief that I’m in the right environment for a beer and the belief that I don’t have any more pressing work. There might also be other things about my history—for instance, having tasted beer before—that contribute to the desire for a beer. And once I have the desire for a beer, I won’t walk into the kitchen if I have the belief that there isn’t a beer in the refrigerator.&lt;/p&gt;

&lt;p&gt;The full story for that desire and for all my other mental states is going to get quite complicated, but if we wanted to do the work, functionalism provides the framework for explaining the entire mind. Since, each mental state is defined by what causes it and what it causes, all that is needed for a complete description of the mind is a description of every mental states’ causal interactions with inputs from the environment, other mental states, and our reactions and behaviors.&lt;/p&gt;

&lt;p&gt;  &lt;/p&gt;

&lt;h5 id=&quot;5-functionalism-consequences-and-a-problem&quot;&gt;&lt;strong&gt;5. Functionalism: Consequences and a Problem&lt;/strong&gt;&lt;/h5&gt;

&lt;p&gt;It’s not a coincidence that functionalism was developed and gained moment at the same time that electronic computers were becoming widely used. Functionalism is often explained by analogy with computer programs, which are also functionally described processes for generating outputs in response to inputs. Given this theory of the mind, then, we have a straightforward answer to the question Can a computer or a robot have a mind? The answer is yes. If the mind is just a series of functionally defined internal states, then not only can a computer have a mind, but our minds are essentially just programs. There are problems with the theory, however, and we’ll examine one of them now.&lt;/p&gt;

&lt;p&gt;Earlier, I said that the mental state that is caused by the belief that it is 6:00 pm and causes walking to the kitchen is &lt;em&gt;the desire for a beer&lt;/em&gt;. Similarly, the mental state that is caused by seeing that it is 6:00 pm and causes the desire for a beer is &lt;em&gt;the belief that it is 6:00 pm&lt;/em&gt;. We can diagram those interactions, with arrows indicating ‘causes’, this way:&lt;/p&gt;

&lt;blockquote&gt;

  &lt;p&gt;&lt;em&gt;seeing that it is 6:00 pm&lt;/em&gt; → &lt;em&gt;the belief that it is 6:00 pm&lt;/em&gt; → &lt;em&gt;desire for a beer&lt;/em&gt;.&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;The mental state in the middle would still be the same mental state if I had called it anything else or simply labeled it x. For instance, in this process:&lt;/p&gt;

&lt;blockquote&gt;

  &lt;p&gt;&lt;em&gt;seeing that it is 6:00 pm&lt;/em&gt; → &lt;em&gt;x&lt;/em&gt; → &lt;em&gt;desire of a beer&lt;/em&gt;&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;x&lt;/em&gt; is still caused by the same perception and it still causes the same desire. According to functionalism, that’s all that there is to &lt;em&gt;the belief that it is 6:00 pm&lt;/em&gt;, or whatever we want to call it.&lt;/p&gt;

&lt;p&gt;Functionalism embraces the implication that a robot could have all of the parts of this process: &lt;em&gt;seeing that it is 6:00 pm&lt;/em&gt; (which is just a perception) &lt;em&gt;the belief that it is 6:00 pm&lt;/em&gt; (which is just the mental state that is caused by that perception), &lt;em&gt;the desire for a beer&lt;/em&gt; (which is a mental state caused by that belief), and &lt;em&gt;walking into the kitchen&lt;/em&gt; (which is an action caused by that desire). It may seem a little odd to say that a robot can have &lt;em&gt;the belief that it is 6:00 pm&lt;/em&gt; or &lt;em&gt;the desire for a beer&lt;/em&gt;, but functionalism may be right that those mental states are nothing more than how they function in that process (and maybe in other processes in the mind). If that’s so, then it’s clear that a robot could have those mental states in its robot mind.&lt;/p&gt;

&lt;p&gt;Now, consider the following. Let’s say that as I’m entering the kitchen to get my beer, I hit my elbow on the door frame. This causes pain, which causes me to utter “ouch!” The mental state here is pain. It is caused by hitting my elbow against the door frame and causes the utterance “ouch!” Again, we can diagram this process this way:&lt;/p&gt;

&lt;blockquote&gt;

  &lt;p&gt;&lt;em&gt;hitting elbow&lt;/em&gt; → &lt;em&gt;pain&lt;/em&gt; → &lt;em&gt;“ouch!”&lt;/em&gt;&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;But unlike &lt;em&gt;the belief that it is 6:00 pm&lt;/em&gt;, for pain, there seems to be more to the mental state than just what causes it and what it then causes. There is also, as we said earlier, a certain kind of experience that accompanies this mental state. A robot could have a mental state that is caused by hitting its elbow on a door frame and which causes it to say “ouch!” But our intuition is that the robot isn’t going to have the experience of pain, or any experience at all, for that matter.&lt;/p&gt;

&lt;p&gt;The problem, then, for functionalism is that this theory doesn’t have an obvious way of characterizing conscious experience. Philosophers have worked to correct this by modifying the theory. One way of doing this is by introducing &lt;em&gt;second-order beliefs&lt;/em&gt;. A second-order belief is a belief about another mental state, and it is in virtue of having a belief about another mental state that the latter becomes a conscious mental state. In other words, mental states become conscious when we think about them.&lt;/p&gt;

&lt;p&gt;Take a belief that, unless you are standing, I am sure that you have right now: the &lt;em&gt;belief that the chair you are sitting in will hold you&lt;/em&gt;. Your behavior gives away that you have it. If you didn’t have this belief, then, unless you were feeling especially daring, you wouldn’t be sitting in that chair. But until you read the last three sentences, the &lt;em&gt;belief that the chair will hold you&lt;/em&gt; was an unconscious belief. It was residing somewhere in your mind outside of consciousness. Now, however, you have a belief about that belief. That is, right now, you have this second-order belief: &lt;em&gt;the belief that you have ‘the belief that the chair will hold you’&lt;/em&gt;, and because you have that second-order belief, &lt;em&gt;the belief that the chair will hold you&lt;/em&gt; has become a conscious belief.&lt;/p&gt;

&lt;p&gt;Similarly, I can have an unconscious desire for a beer, but when I think about that desire, it becomes a conscious desire. In other words, once I form a second-order belief about the desire for a beer, that desire enters consciousness. And let’s say that it is the second-order belief about this desire (&lt;em&gt;the belief that I have ‘a desire for a beer’&lt;/em&gt;) that causes walking to the kitchen. Although it makes functionalism more complex, the idea that thinking about a mental state is what makes that mental state conscious seems to make sense.&lt;/p&gt;

&lt;p&gt;But, while this modification to functionalism works for beliefs and desires, it’s a little bit more of a stretch for a sensation like pain. One issue is whether pain can even be an unconscious mental state. There may be times when someone should be in pain. But if he or she is not having the conscious experience of pain, then, apparently, there just isn’t any pain. But that aside, while we might have to think about a belief for that belief to become conscious, pain appears to be much more direct and immediate. It doesn’t seem quite right to say that we can only have the conscious experience of pain when we have this second-order belief: &lt;em&gt;the belief that I am in pain&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Of course, what doesn’t seem quite right sometimes turns out to be true. But there is also a more significant problem here. The initial charge was that functionalism couldn’t account for consciousness. A creature, such as a robot, that lacked consciousness, could have all of the mental states described in the original version of functionalism. Introducing second-order beliefs doesn’t change that at all. A robot could have second-order beliefs just as well as it could have any other mental states. Just as it can have &lt;em&gt;the belief that it is 6:00 pm&lt;/em&gt;, it can have &lt;em&gt;the belief that it has ‘the belief that it is 6:00 pm’&lt;/em&gt;. But simply by having second-order beliefs, it wouldn’t become a conscious creature. Or put another way, second-order beliefs don’t explain conscious experience, and there’s nothing about second-order beliefs that would make it impossible for an unconscious creature that had other mental states to have them.&lt;/p&gt;

&lt;p&gt;There are other ways that philosophers have attempted to incorporate conscious experience into functionalism, but, despite these attempts, functionalism just doesn’t seem equipped to explain consciousness. Nevertheless, many philosophers, psychologists, and cognitive scientists still consider functionalism a viable theory. In recent years, however, two other theories about the mind have gained momentum.&lt;/p&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Fodor, J. (1989). Making mind matter more. &lt;em&gt;Philosophical Topics&lt;/em&gt;, &lt;em&gt;17&lt;/em&gt;, p. 77. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">These two sections were part of a chapter on the mind. I re-wrote them for the current version of the chapter so that the presentation of functionalism would be a little less technical. This version might still be of interest, however, to anyone looking for a (very) short introduction to the topic. So, here they are.</summary></entry><entry><title type="html">the Monty Hall problem</title><link href="http://localhost:4000/blog/2022/monty-hall/" rel="alternate" type="text/html" title="the Monty Hall problem" /><published>2022-03-14T00:00:00-05:00</published><updated>2022-03-14T00:00:00-05:00</updated><id>http://localhost:4000/blog/2022/monty-hall</id><content type="html" xml:base="http://localhost:4000/blog/2022/monty-hall/">&lt;p&gt;I don’t include the Monty Hall problem in my course, but I have found that, sometimes, someone who knows that I’m teaching inductive logic will ask about it. That happened recently, and we ended up discussed a couple of ways of explaining the solution that I haven’t seen before. So here they are—but first, a quick explanation of the game.&lt;/p&gt;

&lt;p&gt;The Monty Hall problem is named for the original host of &lt;em&gt;Let’s Make a Deal&lt;/em&gt;, although this exact game may not have been on the show. Anyway, let’s say you are a contestant. You are shown three doors. Behind one of the doors is a new car. A goat is behind each of the other two. If you pick the door with the car behind it, you win the car. Otherwise, you lose. (I don’t think that you get to keep the goat, but I’m not sure.) So, you pick a door. Before it is opened, however, Monty Hall opens one of the other two doors, revealing a goat. At this point, with two of the doors still closed, he asks you if you want to switch from the door that you choose to the other one. Should you switch?&lt;/p&gt;

&lt;p&gt;At first glance, it looks like it doesn’t matter. There are two closed doors. Behind one is a goat, and behind the other is a car—apparently, it’s a 50-50 chance. But that’s not right. Originally, there were three options, so when you made your choice, you had a 1/3 chance of selecting correctly. The other two doors, together, comprised a 2/3 chance. When Monty Hall opened a door, however, he knew that he was opening a door that had a goat behind it. (It would ruin the game, or at least end it abruptly, if he opened the door with the car behind it.) So, if there was a 2/3 chance that the car was behind one of the two doors that you didn’t pick, then there is still a 2/3 chance that the car is behind the door that Monty Hall didn’t open. Hence, you should switch from the door that you picked (which has only a 1/3 chance of having a car behind it) to the other closed door (which has a 2/3 chance of having a car behind it).&lt;/p&gt;

&lt;p&gt;Now, two other ways of explaining the solution.&lt;/p&gt;

&lt;p&gt;(a) Instead of three doors, imagine that there are 100 doors. Randomly placed behind the 100 doors are 99 goats and one new car. Just as in the original version of the game, you select a door. Then, before that door is opened, Monty Hall opens 98 of the other doors, revealing 98 goats—and, again, he was only opening doors that he knew had goats behind them. Now there are only two doors that are still closed: the one that you selected and one other. Monty Hall asks you if you want to switch to this other door. Should you? I think it’s more obvious here than in the original version of the game that you should switch. The chance that the car is behind the door that you picked is very small, 1/100. The chance that it is behind one of the other doors is very large, 99/100—and, remember, all that Monty Hall did was open doors that he knew would reveal goats. So there is still the very high chance that the car is behind the one door that he didn’t open, and you should, therefore, switch to that door.&lt;/p&gt;

&lt;p&gt;(b) At the beginning of the game, you pick a door. But now let’s say that Monty Hall offers you this choice: stay with the door that you just picked or switch to one of the two other doors. If you switch, he will open one of those two doors and, at the same time, you will open the other one. If a car is behind either of the two doors, then you will get it. (But we can assume that Monty Hall will open a door that definitely has a goat behind it.) I think it’s clear that you should switch because you get two doors (and a 2/3 chance of winning) instead of only one door (and a 1/3 chance of winning). But except for the timing of when Monty Hall opens his door, this version of the game is the same as the original. Hence, you should switch so that you get the 2/3 chance of winning.&lt;/p&gt;</content><author><name></name></author><category term="inductive-logic" /><summary type="html">I don’t include the Monty Hall problem in my course, but I have found that, sometimes, someone who knows that I’m teaching inductive logic will ask about it. That happened recently, and we ended up discussed a couple of ways of explaining the solution that I haven’t seen before. So here they are—but first, a quick explanation of the game.</summary></entry><entry><title type="html">errata for Argument and Inference</title><link href="http://localhost:4000/blog/2022/errata-arg-and-infer/" rel="alternate" type="text/html" title="errata for Argument and Inference" /><published>2022-03-13T00:00:00-06:00</published><updated>2022-03-13T00:00:00-06:00</updated><id>http://localhost:4000/blog/2022/errata-arg-and-infer</id><content type="html" xml:base="http://localhost:4000/blog/2022/errata-arg-and-infer/">&lt;p&gt;Premise 1 of the induction by confirmation (in chapter 2) should begin with “The hypothesis is …” or “The hypothesis is the following.” If that premise simply states the hypothesis, then the hypothesis can be repeated in the conclusion and the argument will be valid.&lt;/p&gt;

&lt;p&gt;On p. 66, in line 3 of premise 2, it should be “(and possibly on the day that he died)”.&lt;/p&gt;

&lt;p&gt;On p. 141, the last line in table 5.4 should be “30   females who smoke.”&lt;/p&gt;</content><author><name></name></author><category term="inductive-logic" /><summary type="html">Premise 1 of the induction by confirmation (in chapter 2) should begin with “The hypothesis is …” or “The hypothesis is the following.” If that premise simply states the hypothesis, then the hypothesis can be repeated in the conclusion and the argument will be valid.</summary></entry></feed>