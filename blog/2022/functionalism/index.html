<!DOCTYPE html>
<html lang="en">

  <head>
    
        <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>loighic.net | a short introduction to functionalism</title>
    <meta name="author" content="GREGORY  JOHNSON" />
    <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
	
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Noto+Sans:ital,wght@0,300;0,400;0,500;0,600;1,300;1,400;1,500&display=swap" rel="stylesheet">

	
	<!--<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> -->

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ğŸ”¥</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/blog/2022/functionalism/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/">loighic.net</a>
		  
		  
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>


			<!-- CV link -->
			<li class="nav-item"><a class="nav-link" href="/assets/pdf/johnson-cv.pdf">curriculum vitae</a></li> 


              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">teaching</a>
              </li>


              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog</a>
              </li>


              <!-- Toogle theme mode -->
              <div class="toggle-container">
                <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </a>
              </div>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->

    <div class="container mt-5">
      





<div class="post">

  <header class="post-header">
    <h1 class="post-title">a short introduction to functionalism</h1>
    <p class="post-meta">March 18, 2022</p>
    <p class="post-tags">
      <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a>
      

      

    </p>
  </header>

  <article class="post-content">
    <p>These two sections were part of a <a href="https://loighic.net/projects/2_project/" target="_blank" rel="noopener noreferrer">chapter on the mind</a>. I re-wrote them for the current version of the chapter so that the presentation of functionalism would be a little less technical. This version might still be of interest, however, to anyone looking for a (very) short introduction to the topic. So, here they are.</p>

<hr>

<p>Â Â </p>

<h5 id="4-functionalism"><strong>4. Functionalism</strong></h5>

<p>Monismâ€”the idea that the universe is composed of only one substance, matterâ€”is really a category of theories. The version of monism that dominated the second half of the twentieth century began with the philosopher Hilary Putnamâ€™s observation that a mental state such as pain can be experienced by very different kinds of creatures. His examples were mammals, reptiles, octopuses (which are a type of mollusk), and aliens. The first three have, here on earth, taken different evolutionary paths, and so their brains are not that similar. (Of course, the brain of a cat and the brain of a primate are not that similar either, but since they are both mammals and share an evolutionary history, their brains are more similar to each other than either is to a reptile or a mollusk.) Still, mammals, reptiles, and octopuses can all experience pain. And an alien will have yet another type of brain but can still, presumably, experience pain.</p>

<p>Putnamâ€™s response to this observation was to suggest that pain and all other mental states should notâ€”and, in fact, could notâ€”be defined as cellular or molecular or chemical states of the brain. Rather they should be defined in terms of how they <em>function</em>. Pain is not â€œc-fibers firingâ€ (to use a popular example in the philosophical literature). It is rather the mental state that causes me to say â€œouchâ€ and pull back from the stimulus causing the pain.</p>

<p>Before going any further, letâ€™s think a little more about the difference between <em>function</em> and <em>structure</em>. Sitting on my desk is a pen that is mostly made of plastic. The cylinder is clear, the cap is blue, inside the cylinder is a thin tube filled with blue ink, and, at the tip of the pen, is a small ball made of tungsten carbide. Those features of the penâ€”a cylinder a little over 5 inches long and a quarter of an inch in diameter, a small ball at one end, and so forthâ€”are structural features. Without them, the pen wouldnâ€™t exist. But what makes a pen a pen is the <em>function</em> (or the <em>task</em> or the <em>job</em>) that it performs, not itâ€™s specific structural features. It has only one function: <em>facilitating the manual application of ink to a surface</em>, but various structures can perform this function. Instead of plastic, a pen can be made of metal, reed, or a large feather. Instead of a quarter inch in diameter, it can be wider or narrower. Instead of a ball on the end it, it can have a nib (as fountain pens do), a felt tip, or the sharpened end of a feather. But whatever its structure, as long as it performs the correct function, itâ€™s a pen. That insight, that certain things are defined in terms of their function, is the core idea for this theory of the mind, which is called, appropriately enough, <em>functionalism</em>.</p>

<p>So, if I tried to define a pen as <em>a clear plastic cylinder, a little over 5 inches long, a quarter of an inch in diameter, with a small tungsten carbide ball at one end, and blue ink stored in a tube inside the cylinder</em>, that definition would be incorrect. Itâ€™s a description of some pens, but since it leaves out many other instruments that count as pens, it fails as a definition. In other words, pens are <em>multiply realized</em>â€”that is, there are multiple structures that <em>realize</em> (or <em>instantiate</em>) the function <em>facilitating the manual application of ink to a surface</em>. Similarly, at least according to Putnam and many other philosophers, pain and all other mental states are multiply realized. Pain can be instantiated in the mammalian brain, in the reptile brain, in the mollusk brain, and even, presumably, in the alien brain. Consequently, if we try to define pain as a particular sort of activity in the human brain, that definition will be wrong because it leaves out the other kinds of neural activity that are pain in other species.</p>

<p>Weâ€™ll return to functionalism, but letâ€™s clarify one more thing first. By <em>mental states</em>, we mean, for instance, beliefs, desires (i.e., wants), thoughts, ideas (although thoughts and ideas may be the same as beliefs), intentions, sensations, and emotions. Most mental states, although not all, have content. For instance, my <em>belief that today is Thursday</em> is a belief that has the content <em>today is Thursday</em>. Similarly, my <em>desire that it snow this weekend</em> is a desire with the content <em>it snow this weekend</em>.</p>

<p>Functionalism holds that mental states are functional states. It is still a version of monism, though, so it agrees thatâ€”just as a pen has to be instantiated in some physical objectâ€”mental states are instantiated in the brain. But, according to functionalism, we donâ€™t have toâ€”in fact, it would be wrong toâ€”define mental states as particular states of the brain. That gives functionalism a certain appeal. First, because it is a version of monism, it doesnâ€™t have any of the problems that dualism encountered. Second, it allows us to characterize the mind in a way that is very familiar to us. I feel (a mental state!) as though I have beliefs, desires, hopes, fears, and so forth. Furthermore, those mental states, just as Descartes said, seem to define who I am. I might be disappointed if the best theory of the mind told me that the mind is really just a series of neurons firing in the brain. Some people would be more than just disappointed. The philosopher Jerry Fodor, who along with Putnam was instrumental in developing functionalism, says at one point, â€œif it isnâ€™t literally true that my wanting is causally responsible for my reaching, and my itching is causally responsible for my scratching, and my believing is causally responsible for my saying . . . if none of that is literally true, then practically everything I believe about anything is false and itâ€™s the end of the world.â€<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> But luckily for Fodor, functionalism tells us that beliefs, desires, sensations, emotions, and so forth are real and have scientific credibility.</p>

<p>Consider another non-mental example, but one that is more complex than a pen. Here is a simplified description of how a car runs:</p>

<blockquote>

  <p>The <strong>fuel injector</strong> sprays a mixture of air and gasoline at the <strong>intake valve</strong>. The <strong>intake valve</strong> opens letting the air-gas mixture into the <strong>cylinder chamber</strong>. The <strong>piston</strong> compresses the air-gasoline mixture. The <strong>spark plug</strong> emits a spark that ignites the gasoline, which drives the <strong>piston</strong> down the <strong>cylinder chamber</strong>. The downward movement of the <strong>piston</strong> turns the <strong>crankshaft</strong>, which turns the wheels.</p>

</blockquote>

<p>Notice that each component in this system is described in terms of what it doesâ€”that is, itâ€™s functionâ€”not what it is made of. For instance, based on this description, we have no idea what an intake valve looks like or how it is constructed. But that doesnâ€™t really seem to matter because we know that an intake valve is the component that lets the air-gas mixture pass from the fuel injector into the cylinder chamber. <em>Letting the air-gas mixture into the cylinder chamber</em> is the intake valveâ€™s function, and, perhaps, to understand what an intake valve is, thatâ€™s all we need to know.</p>

<p>Now, a mental example:</p>

<blockquote>

  <p>I look at the clock and see that it is 6:00 pm. Seeing that it is 6:00 pm causes <strong>the belief that it is 6:00 pm</strong> which causes the <strong>thought that itâ€™s time to stop working</strong> and the <strong>desire for a beer</strong>. I already have the <strong>belief that there is a beer in the refrigerator</strong>, and so <strong>the belief that there is a beer in the refrigerator</strong> plus my <strong>desire for a beer</strong> cause me to get up and walk toward the kitchen.</p>

</blockquote>

<p>The mental states are <em>the belief that it is 6:00 pm</em>, <em>the thought that itâ€™s time to stop working</em>, <em>the desire for a beer</em>, and <em>the belief that there is a beer in the refrigerator</em>. According to functionalism, this little scenario is the way that we define these mental states. The <em>desire for a beer</em>, at least for me, is the mental state that is caused by <em>the belief that it is 6:00 pm</em> and causes the action: <em>walking into the kitchen</em>. Thatâ€™s a functional characterization of my desire for a beer.</p>

<p>Of course, to be made complete, the description would have to include all of the mental states that can cause the desire for a beer and all of the other mental states and actions that this desire causes. It would also have to include the caveat that the belief that it is 6:00 pm wonâ€™t always cause the desire for a beer. I have to have the belief that Iâ€™m in the right environment for a beer and the belief that I donâ€™t have any more pressing work. There might also be other things about my historyâ€”for instance, having tasted beer beforeâ€”that contribute to the desire for a beer. And once I have the desire for a beer, I wonâ€™t walk into the kitchen if I have the belief that there isnâ€™t a beer in the refrigerator.</p>

<p>The full story for that desire and for all my other mental states is going to get quite complicated, but if we wanted to do the work, functionalism provides the framework for explaining the entire mind. Since, each mental state is defined by what causes it and what it causes, all that is needed for a complete description of the mind is a description of every mental statesâ€™ causal interactions with inputs from the environment, other mental states, and our reactions and behaviors.</p>

<p>Â Â </p>

<h5 id="5-functionalism-consequences-and-a-problem"><strong>5. Functionalism: Consequences and a Problem</strong></h5>

<p>Itâ€™s not a coincidence that functionalism was developed and gained moment at the same time that electronic computers were becoming widely used. Functionalism is often explained by analogy with computer programs, which are also functionally described processes for generating outputs in response to inputs. Given this theory of the mind, then, we have a straightforward answer to the question Can a computer or a robot have a mind? The answer is yes. If the mind is just a series of functionally defined internal states, then not only can a computer have a mind, but our minds are essentially just programs. There are problems with the theory, however, and weâ€™ll examine one of them now.</p>

<p>Earlier, I said that the mental state that is caused by the belief that it is 6:00 pm and causes walking to the kitchen is <em>the desire for a beer</em>. Similarly, the mental state that is caused by seeing that it is 6:00 pm and causes the desire for a beer is <em>the belief that it is 6:00 pm</em>. We can diagram those interactions, with arrows indicating â€˜causesâ€™, this way:</p>

<blockquote>

  <p><em>seeing that it is 6:00 pm</em> â†’ <em>the belief that it is 6:00 pm</em> â†’ <em>desire for a beer</em>.</p>

</blockquote>

<p>The mental state in the middle would still be the same mental state if I had called it anything else or simply labeled it x. For instance, in this process:</p>

<blockquote>

  <p><em>seeing that it is 6:00 pm</em> â†’ <em>x</em> â†’ <em>desire of a beer</em></p>

</blockquote>

<p><em>x</em> is still caused by the same perception and it still causes the same desire. According to functionalism, thatâ€™s all that there is to <em>the belief that it is 6:00 pm</em>, or whatever we want to call it.</p>

<p>Functionalism embraces the implication that a robot could have all of the parts of this process: <em>seeing that it is 6:00 pm</em> (which is just a perception) <em>the belief that it is 6:00 pm</em> (which is just the mental state that is caused by that perception), <em>the desire for a beer</em> (which is a mental state caused by that belief), and <em>walking into the kitchen</em> (which is an action caused by that desire). It may seem a little odd to say that a robot can have <em>the belief that it is 6:00 pm</em> or <em>the desire for a beer</em>, but functionalism may be right that those mental states are nothing more than how they function in that process (and maybe in other processes in the mind). If thatâ€™s so, then itâ€™s clear that a robot could have those mental states in its robot mind.</p>

<p>Now, consider the following. Letâ€™s say that as Iâ€™m entering the kitchen to get my beer, I hit my elbow on the door frame. This causes pain, which causes me to utter â€œouch!â€ The mental state here is pain. It is caused by hitting my elbow against the door frame and causes the utterance â€œouch!â€ Again, we can diagram this process this way:</p>

<blockquote>

  <p><em>hitting elbow</em> â†’ <em>pain</em> â†’ <em>â€œouch!â€</em></p>

</blockquote>

<p>But unlike <em>the belief that it is 6:00 pm</em>, for pain, there seems to be more to the mental state than just what causes it and what it then causes. There is also, as we said earlier, a certain kind of experience that accompanies this mental state. A robot could have a mental state that is caused by hitting its elbow on a door frame and which causes it to say â€œouch!â€ But our intuition is that the robot isnâ€™t going to have the experience of pain, or any experience at all, for that matter.</p>

<p>The problem, then, for functionalism is that this theory doesnâ€™t have an obvious way of characterizing conscious experience. Philosophers have worked to correct this by modifying the theory. One way of doing this is by introducing <em>second-order beliefs</em>. A second-order belief is a belief about another mental state, and it is in virtue of having a belief about another mental state that the latter becomes a conscious mental state. In other words, mental states become conscious when we think about them.</p>

<p>Take a belief that, unless you are standing, I am sure that you have right now: the <em>belief that the chair you are sitting in will hold you</em>. Your behavior gives away that you have it. If you didnâ€™t have this belief, then, unless you were feeling especially daring, you wouldnâ€™t be sitting in that chair. But until you read the last three sentences, the <em>belief that the chair will hold you</em> was an unconscious belief. It was residing somewhere in your mind outside of consciousness. Now, however, you have a belief about that belief. That is, right now, you have this second-order belief: <em>the belief that you have â€˜the belief that the chair will hold youâ€™</em>, and because you have that second-order belief, <em>the belief that the chair will hold you</em> has become a conscious belief.</p>

<p>Similarly, I can have an unconscious desire for a beer, but when I think about that desire, it becomes a conscious desire. In other words, once I form a second-order belief about the desire for a beer, that desire enters consciousness. And letâ€™s say that it is the second-order belief about this desire (<em>the belief that I have â€˜a desire for a beerâ€™</em>) that causes walking to the kitchen. Although it makes functionalism more complex, the idea that thinking about a mental state is what makes that mental state conscious seems to make sense.</p>

<p>But, while this modification to functionalism works for beliefs and desires, itâ€™s a little bit more of a stretch for a sensation like pain. One issue is whether pain can even be an unconscious mental state. There may be times when someone should be in pain. But if he or she is not having the conscious experience of pain, then, apparently, there just isnâ€™t any pain. But that aside, while we might have to think about a belief for that belief to become conscious, pain appears to be much more direct and immediate. It doesnâ€™t seem quite right to say that we can only have the conscious experience of pain when we have this second-order belief: <em>the belief that I am in pain</em>.</p>

<p>Of course, what doesnâ€™t seem quite right sometimes turns out to be true. But there is also a more significant problem here. The initial charge was that functionalism couldnâ€™t account for consciousness. A creature, such as a robot, that lacked consciousness, could have all of the mental states described in the original version of functionalism. Introducing second-order beliefs doesnâ€™t change that at all. A robot could have second-order beliefs just as well as it could have any other mental states. Just as it can have <em>the belief that it is 6:00 pm</em>, it can have <em>the belief that it has â€˜the belief that it is 6:00 pmâ€™</em>. But simply by having second-order beliefs, it wouldnâ€™t become a conscious creature. Or put another way, second-order beliefs donâ€™t explain conscious experience, and thereâ€™s nothing about second-order beliefs that would make it impossible for an unconscious creature that had other mental states to have them.</p>

<p>There are other ways that philosophers have attempted to incorporate conscious experience into functionalism, but, despite these attempts, functionalism just doesnâ€™t seem equipped to explain consciousness. Nevertheless, many philosophers, psychologists, and cognitive scientists still consider functionalism a viable theory. In recent years, however, two other theories about the mind have gained momentum.</p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Fodor, J. (1989). Making mind matter more. <em>Philosophical Topics</em>, <em>17</em>, p. 77.Â <a href="#fnref:1" class="reversefootnote" role="doc-backlink">â†©</a></p>
    </li>
  </ol>
</div>

  </article>

  

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    Â© Copyright 2023 GREGORY  JOHNSON.
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

    
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

  
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  





</html>
